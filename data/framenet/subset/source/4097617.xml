<?xml version="1.0" encoding="utf-8"?>
<command id="4097617">
	<sentence>Technical analysis of clandestine programs is based on the widely known physical and engineering aspects of nuclear materials and weapons , which enable estimates of capabilities based on fragmentary and uncertain information , as follows .</sentence>
	<tokens>
		<token id="1" lemma="Technical" pos="jj" surface="Technical"/>
		<token id="2" lemma="analysis" pos="nn" surface="analysis"/>
		<token id="3" lemma="of" pos="in" surface="of"/>
		<token id="4" lemma="clandestine" pos="jj" surface="clandestine"/>
		<token id="5" lemma="programs" pos="nns" surface="programs"/>
		<token id="6" lemma="is" pos="VBZ" surface="is"/>
		<token id="7" lemma="based" pos="VVN" surface="based"/>
		<token id="8" lemma="on" pos="in" surface="on"/>
		<token id="9" lemma="the" pos="dt" surface="the"/>
		<token id="10" lemma="widely" pos="rb" surface="widely"/>
		<token id="11" lemma="known" pos="VVN" surface="known"/>
		<token id="12" lemma="physical" pos="jj" surface="physical"/>
		<token id="13" lemma="and" pos="cc" surface="and"/>
		<token id="14" lemma="engineering" pos="nn" surface="engineering"/>
		<token id="15" lemma="aspects" pos="nns" surface="aspects"/>
		<token id="16" lemma="of" pos="in" surface="of"/>
		<token id="17" lemma="nuclear" pos="jj" surface="nuclear"/>
		<token id="18" lemma="materials" pos="nns" surface="materials"/>
		<token id="19" lemma="and" pos="cc" surface="and"/>
		<token id="20" lemma="weapons" pos="nns" surface="weapons"/>
		<token id="21" lemma="," pos="," surface=","/>
		<token id="22" lemma="which" pos="wdt" surface="which"/>
		<token id="23" lemma="enable" pos="VVP" surface="enable"/>
		<token id="24" lemma="estimates" pos="nns" surface="estimates"/>
		<token id="25" lemma="of" pos="in" surface="of"/>
		<token id="26" lemma="capabilities" pos="nns" surface="capabilities"/>
		<token id="27" lemma="based" pos="VVN" surface="based"/>
		<token id="28" lemma="on" pos="in" surface="on"/>
		<token id="29" lemma="fragmentary" pos="jj" surface="fragmentary"/>
		<token id="30" lemma="and" pos="cc" surface="and"/>
		<token id="31" lemma="uncertain" pos="jj" surface="uncertain"/>
		<token id="32" lemma="information" pos="nn" surface="information"/>
		<token id="33" lemma="," pos="," surface=","/>
		<token id="34" lemma="as" pos="rb" surface="as"/>
		<token id="35" lemma="follows" pos="VVZ" surface="follows"/>
		<token id="36" lemma="." pos="sent" surface="."/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="2"/>
				</lexicalUnit>
				<frameElement type="Manner">
					<token id="1"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="3"/>
					<token id="4"/>
					<token id="5"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
