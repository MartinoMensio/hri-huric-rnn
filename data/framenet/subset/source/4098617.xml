<?xml version="1.0" encoding="utf-8"?>
<command id="4098617">
	<sentence>QN : Did the Australian Federal Police say that the five million ecstasy tablets seized in Melbourne was the largest seizure of street-ready tablets in the world ?</sentence>
	<tokens>
		<token id="1" lemma="qn" pos="NNP" surface="QN"/>
		<token id="2" lemma=":" pos=":" surface=":"/>
		<token id="3" lemma="do" pos="VBD" surface="Did"/>
		<token id="4" lemma="the" pos="DT" surface="the"/>
		<token id="5" lemma="australian" pos="NNP" surface="Australian"/>
		<token id="6" lemma="federal" pos="NNP" surface="Federal"/>
		<token id="7" lemma="police" pos="NNP" surface="Police"/>
		<token id="8" lemma="say" pos="VBP" surface="say"/>
		<token id="9" lemma="that" pos="IN" surface="that"/>
		<token id="10" lemma="the" pos="DT" surface="the"/>
		<token id="11" lemma="five" pos="CD" surface="five"/>
		<token id="12" lemma="million" pos="CD" surface="million"/>
		<token id="13" lemma="ecstasy" pos="NN" surface="ecstasy"/>
		<token id="14" lemma="tablet" pos="NNS" surface="tablets"/>
		<token id="15" lemma="seize" pos="VBN" surface="seized"/>
		<token id="16" lemma="in" pos="IN" surface="in"/>
		<token id="17" lemma="melbourne" pos="NNP" surface="Melbourne"/>
		<token id="18" lemma="be" pos="VBD" surface="was"/>
		<token id="19" lemma="the" pos="DT" surface="the"/>
		<token id="20" lemma="large" pos="JJS" surface="largest"/>
		<token id="21" lemma="seizure" pos="NN" surface="seizure"/>
		<token id="22" lemma="of" pos="IN" surface="of"/>
		<token id="23" lemma="street-ready" pos="JJ" surface="street-ready"/>
		<token id="24" lemma="tablet" pos="NNS" surface="tablets"/>
		<token id="25" lemma="in" pos="IN" surface="in"/>
		<token id="26" lemma="the" pos="DT" surface="the"/>
		<token id="27" lemma="world" pos="NN" surface="world"/>
		<token id="28" lemma="?" pos="." surface="?"/>
	</tokens>
	<dependencies>
		<dep from="0" to="1" type="root"/>
		<dep from="1" to="2" type="punct"/>
		<dep from="8" to="3" type="aux"/>
		<dep from="7" to="4" type="det"/>
		<dep from="7" to="5" type="compound"/>
		<dep from="7" to="6" type="compound"/>
		<dep from="8" to="7" type="nsubj"/>
		<dep from="0" to="8" type="root"/>
		<dep from="18" to="9" type="mark"/>
		<dep from="14" to="10" type="det"/>
		<dep from="12" to="11" type="compound"/>
		<dep from="14" to="12" type="nummod"/>
		<dep from="14" to="13" type="compound"/>
		<dep from="18" to="14" type="nsubj"/>
		<dep from="14" to="15" type="acl"/>
		<dep from="15" to="16" type="prep"/>
		<dep from="16" to="17" type="pobj"/>
		<dep from="8" to="18" type="ccomp"/>
		<dep from="21" to="19" type="det"/>
		<dep from="21" to="20" type="amod"/>
		<dep from="18" to="21" type="attr"/>
		<dep from="21" to="22" type="prep"/>
		<dep from="24" to="23" type="amod"/>
		<dep from="22" to="24" type="pobj"/>
		<dep from="24" to="25" type="prep"/>
		<dep from="27" to="26" type="det"/>
		<dep from="25" to="27" type="pobj"/>
		<dep from="8" to="28" type="punct"/>
	</dependencies>
	<semantics>
		<frameSemantics>
			<frame name="Taking">
				<lexicalUnit>
					<token id="15"/>
				</lexicalUnit>
				<frameElement type="Theme">
					<token id="9"/>
					<token id="10"/>
					<token id="11"/>
					<token id="12"/>
					<token id="13"/>
					<token id="14"/>
				</frameElement>
				<frameElement type="Place">
					<token id="16"/>
					<token id="17"/>
				</frameElement>
			</frame>
			<frame name="Taking">
				<lexicalUnit>
					<token id="21"/>
				</lexicalUnit>
				<frameElement type="Theme">
					<token id="22"/>
					<token id="23"/>
					<token id="24"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
