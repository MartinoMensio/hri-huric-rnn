<?xml version="1.0" encoding="utf-8"?>
<command id="4096984">
	<sentence>In 2002 , AKU and Damascus University signed a mutual scientific cooperation agreement that called for broadened scientific , educational , and research cooperation between the universities , the exchange of professors and students , the organization of scientific seminars and educational courses , and the formation of a joint working committee to probe into the inauguration of a branch of Amir Kabir University in Syria .</sentence>
	<tokens>
		<token id="1" lemma="In" pos="in" surface="In"/>
		<token id="2" lemma="2002" pos="cd" surface="2002"/>
		<token id="3" lemma="," pos="," surface=","/>
		<token id="4" lemma="AKU" pos="NP" surface="AKU"/>
		<token id="5" lemma="and" pos="cc" surface="and"/>
		<token id="6" lemma="Damascus" pos="NP" surface="Damascus"/>
		<token id="7" lemma="University" pos="NP" surface="University"/>
		<token id="8" lemma="signed" pos="VVD" surface="signed"/>
		<token id="9" lemma="a" pos="dt" surface="a"/>
		<token id="10" lemma="mutual" pos="jj" surface="mutual"/>
		<token id="11" lemma="scientific" pos="jj" surface="scientific"/>
		<token id="12" lemma="cooperation" pos="nn" surface="cooperation"/>
		<token id="13" lemma="agreement" pos="nn" surface="agreement"/>
		<token id="14" lemma="that" pos="wdt" surface="that"/>
		<token id="15" lemma="called" pos="VVD" surface="called"/>
		<token id="16" lemma="for" pos="in" surface="for"/>
		<token id="17" lemma="broadened" pos="VVN" surface="broadened"/>
		<token id="18" lemma="scientific" pos="jj" surface="scientific"/>
		<token id="19" lemma="," pos="," surface=","/>
		<token id="20" lemma="educational" pos="jj" surface="educational"/>
		<token id="21" lemma="," pos="," surface=","/>
		<token id="22" lemma="and" pos="cc" surface="and"/>
		<token id="23" lemma="research" pos="nn" surface="research"/>
		<token id="24" lemma="cooperation" pos="nn" surface="cooperation"/>
		<token id="25" lemma="between" pos="in" surface="between"/>
		<token id="26" lemma="the" pos="dt" surface="the"/>
		<token id="27" lemma="universities" pos="nns" surface="universities"/>
		<token id="28" lemma="," pos="," surface=","/>
		<token id="29" lemma="the" pos="dt" surface="the"/>
		<token id="30" lemma="exchange" pos="nn" surface="exchange"/>
		<token id="31" lemma="of" pos="in" surface="of"/>
		<token id="32" lemma="professors" pos="nns" surface="professors"/>
		<token id="33" lemma="and" pos="cc" surface="and"/>
		<token id="34" lemma="students" pos="nns" surface="students"/>
		<token id="35" lemma="," pos="," surface=","/>
		<token id="36" lemma="the" pos="dt" surface="the"/>
		<token id="37" lemma="organization" pos="nn" surface="organization"/>
		<token id="38" lemma="of" pos="in" surface="of"/>
		<token id="39" lemma="scientific" pos="jj" surface="scientific"/>
		<token id="40" lemma="seminars" pos="nns" surface="seminars"/>
		<token id="41" lemma="and" pos="cc" surface="and"/>
		<token id="42" lemma="educational" pos="jj" surface="educational"/>
		<token id="43" lemma="courses" pos="nns" surface="courses"/>
		<token id="44" lemma="," pos="," surface=","/>
		<token id="45" lemma="and" pos="cc" surface="and"/>
		<token id="46" lemma="the" pos="dt" surface="the"/>
		<token id="47" lemma="formation" pos="nn" surface="formation"/>
		<token id="48" lemma="of" pos="in" surface="of"/>
		<token id="49" lemma="a" pos="dt" surface="a"/>
		<token id="50" lemma="joint" pos="jj" surface="joint"/>
		<token id="51" lemma="working" pos="VVG" surface="working"/>
		<token id="52" lemma="committee" pos="nn" surface="committee"/>
		<token id="53" lemma="to" pos="to" surface="to"/>
		<token id="54" lemma="probe" pos="VV" surface="probe"/>
		<token id="55" lemma="into" pos="in" surface="into"/>
		<token id="56" lemma="the" pos="dt" surface="the"/>
		<token id="57" lemma="inauguration" pos="nn" surface="inauguration"/>
		<token id="58" lemma="of" pos="in" surface="of"/>
		<token id="59" lemma="a" pos="dt" surface="a"/>
		<token id="60" lemma="branch" pos="nn" surface="branch"/>
		<token id="61" lemma="of" pos="in" surface="of"/>
		<token id="62" lemma="Amir" pos="NP" surface="Amir"/>
		<token id="63" lemma="Kabir" pos="NP" surface="Kabir"/>
		<token id="64" lemma="University" pos="NP" surface="University"/>
		<token id="65" lemma="in" pos="in" surface="in"/>
		<token id="66" lemma="Syria" pos="NP" surface="Syria"/>
		<token id="67" lemma="." pos="sent" surface="."/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="54"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="49"/>
					<token id="50"/>
					<token id="51"/>
					<token id="52"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="55"/>
					<token id="56"/>
					<token id="57"/>
					<token id="58"/>
					<token id="59"/>
					<token id="60"/>
					<token id="61"/>
					<token id="62"/>
					<token id="63"/>
					<token id="64"/>
					<token id="65"/>
					<token id="66"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
