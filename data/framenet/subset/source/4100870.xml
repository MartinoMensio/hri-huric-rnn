<?xml version="1.0" encoding="utf-8"?>
<command id="4100870">
	<sentence>The nuclear agency had hoped to monitor the larger centrifuge cascade with cameras , but Iranian officials were `` not allowing the IAEA to install the cameras inside the cascade halls in Natanz and are causing further delays in the inspectors ' activity , '' a diplomat who closely monitors the agency said yesterday .</sentence>
	<tokens>
		<token id="1" lemma="the" pos="DT" surface="The"/>
		<token id="2" lemma="nuclear" pos="JJ" surface="nuclear"/>
		<token id="3" lemma="agency" pos="NN" surface="agency"/>
		<token id="4" lemma="have" pos="VBD" surface="had"/>
		<token id="5" lemma="hop" pos="VBN" surface="hoped"/>
		<token id="6" lemma="to" pos="TO" surface="to"/>
		<token id="7" lemma="monitor" pos="VB" surface="monitor"/>
		<token id="8" lemma="the" pos="DT" surface="the"/>
		<token id="9" lemma="large" pos="JJR" surface="larger"/>
		<token id="10" lemma="centrifuge" pos="NN" surface="centrifuge"/>
		<token id="11" lemma="cascade" pos="NN" surface="cascade"/>
		<token id="12" lemma="with" pos="IN" surface="with"/>
		<token id="13" lemma="camera" pos="NNS" surface="cameras"/>
		<token id="14" lemma="," pos="," surface=","/>
		<token id="15" lemma="but" pos="CC" surface="but"/>
		<token id="16" lemma="iranian" pos="JJ" surface="Iranian"/>
		<token id="17" lemma="official" pos="NNS" surface="officials"/>
		<token id="18" lemma="be" pos="VBD" surface="were"/>
		<token id="19" lemma="``" pos="``" surface="``"/>
		<token id="20" lemma="not" pos="RB" surface="not"/>
		<token id="21" lemma="allow" pos="VBG" surface="allowing"/>
		<token id="22" lemma="the" pos="DT" surface="the"/>
		<token id="23" lemma="iaea" pos="NNP" surface="IAEA"/>
		<token id="24" lemma="to" pos="TO" surface="to"/>
		<token id="25" lemma="install" pos="VB" surface="install"/>
		<token id="26" lemma="the" pos="DT" surface="the"/>
		<token id="27" lemma="camera" pos="NNS" surface="cameras"/>
		<token id="28" lemma="inside" pos="IN" surface="inside"/>
		<token id="29" lemma="the" pos="DT" surface="the"/>
		<token id="30" lemma="cascade" pos="NN" surface="cascade"/>
		<token id="31" lemma="hall" pos="NNS" surface="halls"/>
		<token id="32" lemma="in" pos="IN" surface="in"/>
		<token id="33" lemma="natanz" pos="NNP" surface="Natanz"/>
		<token id="34" lemma="and" pos="CC" surface="and"/>
		<token id="35" lemma="be" pos="VBP" surface="are"/>
		<token id="36" lemma="cause" pos="VBG" surface="causing"/>
		<token id="37" lemma="further" pos="JJ" surface="further"/>
		<token id="38" lemma="delay" pos="NNS" surface="delays"/>
		<token id="39" lemma="in" pos="IN" surface="in"/>
		<token id="40" lemma="the" pos="DT" surface="the"/>
		<token id="41" lemma="inspector" pos="NNS" surface="inspectors"/>
		<token id="42" lemma="'" pos="POS" surface="'"/>
		<token id="43" lemma="activity" pos="NN" surface="activity"/>
		<token id="44" lemma="," pos="," surface=","/>
		<token id="45" lemma="''" pos="''" surface="''"/>
		<token id="46" lemma="a" pos="DT" surface="a"/>
		<token id="47" lemma="diplomat" pos="NN" surface="diplomat"/>
		<token id="48" lemma="who" pos="WP" surface="who"/>
		<token id="49" lemma="closely" pos="RB" surface="closely"/>
		<token id="50" lemma="monitor" pos="VBZ" surface="monitors"/>
		<token id="51" lemma="the" pos="DT" surface="the"/>
		<token id="52" lemma="agency" pos="NN" surface="agency"/>
		<token id="53" lemma="say" pos="VBD" surface="said"/>
		<token id="54" lemma="yesterday" pos="NN" surface="yesterday"/>
		<token id="55" lemma="." pos="." surface="."/>
	</tokens>
	<dependencies>
		<dep from="3" to="1" type="det"/>
		<dep from="3" to="2" type="amod"/>
		<dep from="5" to="3" type="nsubj"/>
		<dep from="5" to="4" type="aux"/>
		<dep from="53" to="5" type="ccomp"/>
		<dep from="7" to="6" type="aux"/>
		<dep from="5" to="7" type="xcomp"/>
		<dep from="11" to="8" type="det"/>
		<dep from="11" to="9" type="amod"/>
		<dep from="11" to="10" type="compound"/>
		<dep from="7" to="11" type="dobj"/>
		<dep from="11" to="12" type="prep"/>
		<dep from="12" to="13" type="pobj"/>
		<dep from="5" to="14" type="punct"/>
		<dep from="5" to="15" type="cc"/>
		<dep from="17" to="16" type="amod"/>
		<dep from="21" to="17" type="nsubj"/>
		<dep from="21" to="18" type="aux"/>
		<dep from="21" to="19" type="punct"/>
		<dep from="21" to="20" type="neg"/>
		<dep from="5" to="21" type="conj"/>
		<dep from="23" to="22" type="det"/>
		<dep from="25" to="23" type="nsubj"/>
		<dep from="25" to="24" type="aux"/>
		<dep from="21" to="25" type="ccomp"/>
		<dep from="27" to="26" type="det"/>
		<dep from="25" to="27" type="dobj"/>
		<dep from="27" to="28" type="prep"/>
		<dep from="31" to="29" type="det"/>
		<dep from="31" to="30" type="compound"/>
		<dep from="28" to="31" type="pobj"/>
		<dep from="31" to="32" type="prep"/>
		<dep from="32" to="33" type="pobj"/>
		<dep from="21" to="34" type="cc"/>
		<dep from="36" to="35" type="aux"/>
		<dep from="21" to="36" type="conj"/>
		<dep from="38" to="37" type="amod"/>
		<dep from="36" to="38" type="dobj"/>
		<dep from="36" to="39" type="prep"/>
		<dep from="41" to="40" type="det"/>
		<dep from="43" to="41" type="poss"/>
		<dep from="41" to="42" type="case"/>
		<dep from="39" to="43" type="pobj"/>
		<dep from="53" to="44" type="punct"/>
		<dep from="44" to="45" type="punct"/>
		<dep from="47" to="46" type="det"/>
		<dep from="53" to="47" type="nsubj"/>
		<dep from="50" to="48" type="nsubj"/>
		<dep from="50" to="49" type="advmod"/>
		<dep from="47" to="50" type="relcl"/>
		<dep from="52" to="51" type="det"/>
		<dep from="50" to="52" type="dobj"/>
		<dep from="0" to="53" type="root"/>
		<dep from="53" to="54" type="npadvmod"/>
		<dep from="53" to="55" type="punct"/>
	</dependencies>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="7"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="1"/>
					<token id="2"/>
					<token id="3"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="8"/>
					<token id="9"/>
					<token id="10"/>
					<token id="11"/>
				</frameElement>
				<frameElement type="Instrument">
					<token id="12"/>
					<token id="13"/>
				</frameElement>
			</frame>
			<frame name="Searching">
				<lexicalUnit>
					<token id="41"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="41"/>
				</frameElement>
			</frame>
			<frame name="Searching">
				<lexicalUnit>
					<token id="50"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="46"/>
					<token id="47"/>
				</frameElement>
				<frameElement type="Cognizer">
					<token id="48"/>
				</frameElement>
				<frameElement type="Degree">
					<token id="49"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="51"/>
					<token id="52"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
