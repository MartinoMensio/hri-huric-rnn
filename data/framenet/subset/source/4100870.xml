<?xml version="1.0" encoding="utf-8"?>
<command id="4100870">
	<sentence>The nuclear agency had hoped to monitor the larger centrifuge cascade with cameras , but Iranian officials were `` not allowing the IAEA to install the cameras inside the cascade halls in Natanz and are causing further delays in the inspectors ' activity , '' a diplomat who closely monitors the agency said yesterday .</sentence>
	<tokens>
		<token id="1" lemma="The" pos="dt" surface="The"/>
		<token id="2" lemma="nuclear" pos="jj" surface="nuclear"/>
		<token id="3" lemma="agency" pos="nn" surface="agency"/>
		<token id="4" lemma="had" pos="VHD" surface="had"/>
		<token id="5" lemma="hoped" pos="VVN" surface="hoped"/>
		<token id="6" lemma="to" pos="to" surface="to"/>
		<token id="7" lemma="monitor" pos="VV" surface="monitor"/>
		<token id="8" lemma="the" pos="dt" surface="the"/>
		<token id="9" lemma="larger" pos="jjr" surface="larger"/>
		<token id="10" lemma="centrifuge" pos="nn" surface="centrifuge"/>
		<token id="11" lemma="cascade" pos="nn" surface="cascade"/>
		<token id="12" lemma="with" pos="in" surface="with"/>
		<token id="13" lemma="cameras" pos="nns" surface="cameras"/>
		<token id="14" lemma="," pos="," surface=","/>
		<token id="15" lemma="but" pos="cc" surface="but"/>
		<token id="16" lemma="Iranian" pos="jj" surface="Iranian"/>
		<token id="17" lemma="officials" pos="nns" surface="officials"/>
		<token id="18" lemma="were" pos="VBD" surface="were"/>
		<token id="19" lemma="``" pos="``" surface="``"/>
		<token id="20" lemma="not" pos="rb" surface="not"/>
		<token id="21" lemma="allowing" pos="VVG" surface="allowing"/>
		<token id="22" lemma="the" pos="dt" surface="the"/>
		<token id="23" lemma="IAEA" pos="nn" surface="IAEA"/>
		<token id="24" lemma="to" pos="to" surface="to"/>
		<token id="25" lemma="install" pos="VV" surface="install"/>
		<token id="26" lemma="the" pos="dt" surface="the"/>
		<token id="27" lemma="cameras" pos="nns" surface="cameras"/>
		<token id="28" lemma="inside" pos="in" surface="inside"/>
		<token id="29" lemma="the" pos="dt" surface="the"/>
		<token id="30" lemma="cascade" pos="nn" surface="cascade"/>
		<token id="31" lemma="halls" pos="nns" surface="halls"/>
		<token id="32" lemma="in" pos="in" surface="in"/>
		<token id="33" lemma="Natanz" pos="NP" surface="Natanz"/>
		<token id="34" lemma="and" pos="cc" surface="and"/>
		<token id="35" lemma="are" pos="vbp" surface="are"/>
		<token id="36" lemma="causing" pos="VVG" surface="causing"/>
		<token id="37" lemma="further" pos="jj" surface="further"/>
		<token id="38" lemma="delays" pos="nns" surface="delays"/>
		<token id="39" lemma="in" pos="in" surface="in"/>
		<token id="40" lemma="the" pos="dt" surface="the"/>
		<token id="41" lemma="inspectors" pos="nns" surface="inspectors"/>
		<token id="42" lemma="'" pos="POS" surface="'"/>
		<token id="43" lemma="activity" pos="nn" surface="activity"/>
		<token id="44" lemma="," pos="," surface=","/>
		<token id="45" lemma="''" pos="''" surface="''"/>
		<token id="46" lemma="a" pos="dt" surface="a"/>
		<token id="47" lemma="diplomat" pos="nn" surface="diplomat"/>
		<token id="48" lemma="who" pos="wp" surface="who"/>
		<token id="49" lemma="closely" pos="rb" surface="closely"/>
		<token id="50" lemma="monitors" pos="VVZ" surface="monitors"/>
		<token id="51" lemma="the" pos="dt" surface="the"/>
		<token id="52" lemma="agency" pos="nn" surface="agency"/>
		<token id="53" lemma="said" pos="VVD" surface="said"/>
		<token id="54" lemma="yesterday" pos="nn" surface="yesterday"/>
		<token id="55" lemma="." pos="sent" surface="."/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="7"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="1"/>
					<token id="2"/>
					<token id="3"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="8"/>
					<token id="9"/>
					<token id="10"/>
					<token id="11"/>
				</frameElement>
				<frameElement type="Instrument">
					<token id="12"/>
					<token id="13"/>
				</frameElement>
			</frame>
			<frame name="Searching">
				<lexicalUnit>
					<token id="41"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="41"/>
				</frameElement>
			</frame>
			<frame name="Searching">
				<lexicalUnit>
					<token id="50"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="46"/>
					<token id="47"/>
				</frameElement>
				<frameElement type="Cognizer">
					<token id="48"/>
				</frameElement>
				<frameElement type="Degree">
					<token id="49"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="51"/>
					<token id="52"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
