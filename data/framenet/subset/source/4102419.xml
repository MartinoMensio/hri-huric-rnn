<?xml version="1.0" encoding="utf-8"?>
<command id="4102419">
	<sentence>Harry_Reed : This investigation has been stymied stopped , obstructions thrown up every step of the way .</sentence>
	<tokens>
		<token id="1" lemma="harry_reed" pos="NN" surface="Harry_Reed"/>
		<token id="2" lemma=":" pos=":" surface=":"/>
		<token id="3" lemma="this" pos="DT" surface="This"/>
		<token id="4" lemma="investigation" pos="NN" surface="investigation"/>
		<token id="5" lemma="have" pos="VBZ" surface="has"/>
		<token id="6" lemma="be" pos="VBN" surface="been"/>
		<token id="7" lemma="stymie" pos="VBN" surface="stymied"/>
		<token id="8" lemma="stop" pos="VBN" surface="stopped"/>
		<token id="9" lemma="," pos="," surface=","/>
		<token id="10" lemma="obstruction" pos="NNS" surface="obstructions"/>
		<token id="11" lemma="throw" pos="VBN" surface="thrown"/>
		<token id="12" lemma="up" pos="RP" surface="up"/>
		<token id="13" lemma="every" pos="DT" surface="every"/>
		<token id="14" lemma="step" pos="NN" surface="step"/>
		<token id="15" lemma="of" pos="IN" surface="of"/>
		<token id="16" lemma="the" pos="DT" surface="the"/>
		<token id="17" lemma="way" pos="NN" surface="way"/>
		<token id="18" lemma="." pos="." surface="."/>
	</tokens>
	<dependencies>
		<dep from="0" to="1" type="root"/>
		<dep from="1" to="2" type="punct"/>
		<dep from="4" to="3" type="det"/>
		<dep from="7" to="4" type="nsubjpass"/>
		<dep from="7" to="5" type="aux"/>
		<dep from="7" to="6" type="auxpass"/>
		<dep from="11" to="7" type="ccomp"/>
		<dep from="7" to="8" type="advcl"/>
		<dep from="11" to="9" type="punct"/>
		<dep from="11" to="10" type="nsubj"/>
		<dep from="0" to="11" type="root"/>
		<dep from="11" to="12" type="prt"/>
		<dep from="14" to="13" type="det"/>
		<dep from="11" to="14" type="dobj"/>
		<dep from="14" to="15" type="prep"/>
		<dep from="17" to="16" type="det"/>
		<dep from="15" to="17" type="pobj"/>
		<dep from="11" to="18" type="punct"/>
	</dependencies>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="4"/>
				</lexicalUnit>
			</frame>
		</frameSemantics>
	</semantics>
</command>
