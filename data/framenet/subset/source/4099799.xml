<?xml version="1.0" encoding="utf-8"?>
<command id="4099799">
	<sentence>They were there to study migrating birds , information the military would use to determine if chemicals and diseases could be transported across borders and so be used as vectors by -- or against -- an enemy .</sentence>
	<tokens>
		<token id="1" lemma="They" pos="PP" surface="They"/>
		<token id="2" lemma="were" pos="VBD" surface="were"/>
		<token id="3" lemma="there" pos="rb" surface="there"/>
		<token id="4" lemma="to" pos="to" surface="to"/>
		<token id="5" lemma="study" pos="VV" surface="study"/>
		<token id="6" lemma="migrating" pos="VVG" surface="migrating"/>
		<token id="7" lemma="birds" pos="nns" surface="birds"/>
		<token id="8" lemma="," pos="," surface=","/>
		<token id="9" lemma="information" pos="nn" surface="information"/>
		<token id="10" lemma="the" pos="dt" surface="the"/>
		<token id="11" lemma="military" pos="nn" surface="military"/>
		<token id="12" lemma="would" pos="md" surface="would"/>
		<token id="13" lemma="use" pos="VV" surface="use"/>
		<token id="14" lemma="to" pos="to" surface="to"/>
		<token id="15" lemma="determine" pos="VV" surface="determine"/>
		<token id="16" lemma="if" pos="in" surface="if"/>
		<token id="17" lemma="chemicals" pos="nns" surface="chemicals"/>
		<token id="18" lemma="and" pos="cc" surface="and"/>
		<token id="19" lemma="diseases" pos="nns" surface="diseases"/>
		<token id="20" lemma="could" pos="md" surface="could"/>
		<token id="21" lemma="be" pos="vb" surface="be"/>
		<token id="22" lemma="transported" pos="VVN" surface="transported"/>
		<token id="23" lemma="across" pos="in" surface="across"/>
		<token id="24" lemma="borders" pos="nns" surface="borders"/>
		<token id="25" lemma="and" pos="cc" surface="and"/>
		<token id="26" lemma="so" pos="rb" surface="so"/>
		<token id="27" lemma="be" pos="vb" surface="be"/>
		<token id="28" lemma="used" pos="VVN" surface="used"/>
		<token id="29" lemma="as" pos="in" surface="as"/>
		<token id="30" lemma="vectors" pos="nns" surface="vectors"/>
		<token id="31" lemma="by" pos="in" surface="by"/>
		<token id="32" lemma="--" pos=":" surface="--"/>
		<token id="33" lemma="or" pos="cc" surface="or"/>
		<token id="34" lemma="against" pos="in" surface="against"/>
		<token id="35" lemma="--" pos=":" surface="--"/>
		<token id="36" lemma="an" pos="dt" surface="an"/>
		<token id="37" lemma="enemy" pos="nn" surface="enemy"/>
		<token id="38" lemma="." pos="sent" surface="."/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="5"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="1"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="6"/>
					<token id="7"/>
				</frameElement>
			</frame>
			<frame name="Bringing">
				<lexicalUnit>
					<token id="22"/>
				</lexicalUnit>
				<frameElement type="Theme">
					<token id="17"/>
					<token id="18"/>
					<token id="19"/>
				</frameElement>
				<frameElement type="Path">
					<token id="23"/>
					<token id="24"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
