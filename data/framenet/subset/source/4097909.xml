<?xml version="1.0" encoding="utf-8"?>
<command id="4097909">
	<sentence>The extent to which various foreign governments , military establishments , and intelligence agencies secretly monitored or covertly assisted in the development of the program likewise remains an open question .</sentence>
	<tokens>
		<token id="1" lemma="The" pos="dt" surface="The"/>
		<token id="2" lemma="extent" pos="nn" surface="extent"/>
		<token id="3" lemma="to" pos="to" surface="to"/>
		<token id="4" lemma="which" pos="wdt" surface="which"/>
		<token id="5" lemma="various" pos="jj" surface="various"/>
		<token id="6" lemma="foreign" pos="jj" surface="foreign"/>
		<token id="7" lemma="governments" pos="nns" surface="governments"/>
		<token id="8" lemma="," pos="," surface=","/>
		<token id="9" lemma="military" pos="jj" surface="military"/>
		<token id="10" lemma="establishments" pos="nns" surface="establishments"/>
		<token id="11" lemma="," pos="," surface=","/>
		<token id="12" lemma="and" pos="cc" surface="and"/>
		<token id="13" lemma="intelligence" pos="nn" surface="intelligence"/>
		<token id="14" lemma="agencies" pos="nns" surface="agencies"/>
		<token id="15" lemma="secretly" pos="rb" surface="secretly"/>
		<token id="16" lemma="monitored" pos="VVN" surface="monitored"/>
		<token id="17" lemma="or" pos="cc" surface="or"/>
		<token id="18" lemma="covertly" pos="rb" surface="covertly"/>
		<token id="19" lemma="assisted" pos="VVN" surface="assisted"/>
		<token id="20" lemma="in" pos="in" surface="in"/>
		<token id="21" lemma="the" pos="dt" surface="the"/>
		<token id="22" lemma="development" pos="nn" surface="development"/>
		<token id="23" lemma="of" pos="in" surface="of"/>
		<token id="24" lemma="the" pos="dt" surface="the"/>
		<token id="25" lemma="program" pos="nn" surface="program"/>
		<token id="26" lemma="likewise" pos="rb" surface="likewise"/>
		<token id="27" lemma="remains" pos="VVZ" surface="remains"/>
		<token id="28" lemma="an" pos="dt" surface="an"/>
		<token id="29" lemma="open" pos="jj" surface="open"/>
		<token id="30" lemma="question" pos="nn" surface="question"/>
		<token id="31" lemma="." pos="sent" surface="."/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="16"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="6"/>
					<token id="7"/>
					<token id="8"/>
					<token id="9"/>
					<token id="10"/>
					<token id="11"/>
					<token id="12"/>
					<token id="13"/>
					<token id="14"/>
				</frameElement>
				<frameElement type="Manner">
					<token id="15"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="21"/>
					<token id="22"/>
					<token id="23"/>
					<token id="24"/>
					<token id="25"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
