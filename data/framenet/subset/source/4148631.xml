<?xml version="1.0" encoding="utf-8"?>
<command id="4148631">
	<sentence>It is grotesque , Watson , &quot; Holmes added , as he slowly fastened his notebook , &quot; but , as I have had occasion to remark , there is but one step from the grotesque to the horrible . &quot;</sentence>
	<tokens>
		<token id="1" lemma="It" pos="PRP" surface="It"/>
		<token id="2" lemma="is" pos="VBZ" surface="is"/>
		<token id="3" lemma="grotesque" pos="jj" surface="grotesque"/>
		<token id="4" lemma="Watson" pos="NNP" surface="Watson"/>
		<token id="5" lemma="Holmes" pos="NNP" surface="Holmes"/>
		<token id="6" lemma="added" pos="VBD" surface="added"/>
		<token id="7" lemma="as" pos="in" surface="as"/>
		<token id="8" lemma="he" pos="PRP" surface="he"/>
		<token id="9" lemma="slowly" pos="rb" surface="slowly"/>
		<token id="10" lemma="fastened" pos="VBN" surface="fastened"/>
		<token id="11" lemma="his" pos="PRP$" surface="his"/>
		<token id="12" lemma="notebook" pos="nn" surface="notebook"/>
		<token id="13" lemma="but" pos="cc" surface="but"/>
		<token id="14" lemma="as" pos="in" surface="as"/>
		<token id="15" lemma="I" pos="PRP" surface="I"/>
		<token id="16" lemma="have" pos="vbp" surface="have"/>
		<token id="17" lemma="had" pos="VBN" surface="had"/>
		<token id="18" lemma="occasion" pos="nn" surface="occasion"/>
		<token id="19" lemma="to" pos="to" surface="to"/>
		<token id="20" lemma="remark" pos="vb" surface="remark"/>
		<token id="21" lemma="there" pos="ex" surface="there"/>
		<token id="22" lemma="is" pos="VBZ" surface="is"/>
		<token id="23" lemma="but" pos="rb" surface="but"/>
		<token id="24" lemma="one" pos="cd" surface="one"/>
		<token id="25" lemma="step" pos="nn" surface="step"/>
		<token id="26" lemma="from" pos="in" surface="from"/>
		<token id="27" lemma="the" pos="dt" surface="the"/>
		<token id="28" lemma="grotesque" pos="jj" surface="grotesque"/>
		<token id="29" lemma="to" pos="to" surface="to"/>
		<token id="30" lemma="the" pos="dt" surface="the"/>
		<token id="31" lemma="horrible" pos="jj" surface="horrible"/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Closure">
				<lexicalUnit>
					<token id="10"/>
				</lexicalUnit>
				<frameElement type="Containing_object">
					<token id="11"/>
					<token id="12"/>
				</frameElement>
				<frameElement type="Agent">
					<token id="8"/>
				</frameElement>
				<frameElement type="Manner">
					<token id="9"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
