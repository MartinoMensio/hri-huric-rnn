<?xml version="1.0" encoding="utf-8"?>
<command id="4096960">
	<sentence>Like many facilities throughout the United States and Western Europe that have similar or even more advanced capabilities , these facilities are open to public scrutiny .</sentence>
	<tokens>
		<token id="1" lemma="like" pos="IN" surface="Like"/>
		<token id="2" lemma="many" pos="JJ" surface="many"/>
		<token id="3" lemma="facility" pos="NNS" surface="facilities"/>
		<token id="4" lemma="throughout" pos="IN" surface="throughout"/>
		<token id="5" lemma="the" pos="DT" surface="the"/>
		<token id="6" lemma="united" pos="NNP" surface="United"/>
		<token id="7" lemma="states" pos="NNP" surface="States"/>
		<token id="8" lemma="and" pos="CC" surface="and"/>
		<token id="9" lemma="western" pos="NNP" surface="Western"/>
		<token id="10" lemma="europe" pos="NNP" surface="Europe"/>
		<token id="11" lemma="that" pos="WDT" surface="that"/>
		<token id="12" lemma="have" pos="VBP" surface="have"/>
		<token id="13" lemma="similar" pos="JJ" surface="similar"/>
		<token id="14" lemma="or" pos="CC" surface="or"/>
		<token id="15" lemma="even" pos="RB" surface="even"/>
		<token id="16" lemma="more" pos="RBR" surface="more"/>
		<token id="17" lemma="advanced" pos="JJ" surface="advanced"/>
		<token id="18" lemma="capability" pos="NNS" surface="capabilities"/>
		<token id="19" lemma="," pos="," surface=","/>
		<token id="20" lemma="these" pos="DT" surface="these"/>
		<token id="21" lemma="facility" pos="NNS" surface="facilities"/>
		<token id="22" lemma="be" pos="VBP" surface="are"/>
		<token id="23" lemma="open" pos="JJ" surface="open"/>
		<token id="24" lemma="to" pos="IN" surface="to"/>
		<token id="25" lemma="public" pos="JJ" surface="public"/>
		<token id="26" lemma="scrutiny" pos="NN" surface="scrutiny"/>
		<token id="27" lemma="." pos="." surface="."/>
	</tokens>
	<dependencies>
		<dep from="22" to="1" type="prep"/>
		<dep from="3" to="2" type="amod"/>
		<dep from="1" to="3" type="pobj"/>
		<dep from="3" to="4" type="prep"/>
		<dep from="7" to="5" type="det"/>
		<dep from="7" to="6" type="compound"/>
		<dep from="4" to="7" type="pobj"/>
		<dep from="7" to="8" type="cc"/>
		<dep from="10" to="9" type="compound"/>
		<dep from="7" to="10" type="conj"/>
		<dep from="12" to="11" type="nsubj"/>
		<dep from="3" to="12" type="relcl"/>
		<dep from="18" to="13" type="amod"/>
		<dep from="13" to="14" type="cc"/>
		<dep from="16" to="15" type="advmod"/>
		<dep from="17" to="16" type="advmod"/>
		<dep from="13" to="17" type="conj"/>
		<dep from="12" to="18" type="dobj"/>
		<dep from="22" to="19" type="punct"/>
		<dep from="21" to="20" type="det"/>
		<dep from="22" to="21" type="nsubj"/>
		<dep from="0" to="22" type="root"/>
		<dep from="22" to="23" type="acomp"/>
		<dep from="23" to="24" type="prep"/>
		<dep from="26" to="25" type="amod"/>
		<dep from="24" to="26" type="pobj"/>
		<dep from="22" to="27" type="punct"/>
	</dependencies>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="26"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="25"/>
				</frameElement>
				<frameElement type="Ground">
					<token id="20"/>
					<token id="21"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
