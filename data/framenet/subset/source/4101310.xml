<?xml version="1.0" encoding="utf-8"?>
<command id="4101310">
	<sentence>The Iraqi government has agreed to let U.S. Rep . Tony Hall visit the country next week to assess a humanitarian crisis that has festered since the Gulf War of 1990 , Hall 's office said Monday .</sentence>
	<tokens>
		<token id="1" lemma="The" pos="dt" surface="The"/>
		<token id="2" lemma="Iraqi" pos="jj" surface="Iraqi"/>
		<token id="3" lemma="government" pos="nn" surface="government"/>
		<token id="4" lemma="has" pos="VHZ" surface="has"/>
		<token id="5" lemma="agreed" pos="VVN" surface="agreed"/>
		<token id="6" lemma="to" pos="to" surface="to"/>
		<token id="7" lemma="let" pos="VV" surface="let"/>
		<token id="8" lemma="U.S." pos="NP" surface="U.S."/>
		<token id="9" lemma="Rep" pos="NP" surface="Rep"/>
		<token id="10" lemma="." pos="sent" surface="."/>
		<token id="11" lemma="Tony" pos="NP" surface="Tony"/>
		<token id="12" lemma="Hall" pos="NP" surface="Hall"/>
		<token id="13" lemma="visit" pos="VV" surface="visit"/>
		<token id="14" lemma="the" pos="dt" surface="the"/>
		<token id="15" lemma="country" pos="nn" surface="country"/>
		<token id="16" lemma="next" pos="in" surface="next"/>
		<token id="17" lemma="week" pos="nn" surface="week"/>
		<token id="18" lemma="to" pos="to" surface="to"/>
		<token id="19" lemma="assess" pos="VV" surface="assess"/>
		<token id="20" lemma="a" pos="dt" surface="a"/>
		<token id="21" lemma="humanitarian" pos="jj" surface="humanitarian"/>
		<token id="22" lemma="crisis" pos="nn" surface="crisis"/>
		<token id="23" lemma="that" pos="wdt" surface="that"/>
		<token id="24" lemma="has" pos="VHZ" surface="has"/>
		<token id="25" lemma="festered" pos="VVN" surface="festered"/>
		<token id="26" lemma="since" pos="in" surface="since"/>
		<token id="27" lemma="the" pos="dt" surface="the"/>
		<token id="28" lemma="Gulf" pos="NP" surface="Gulf"/>
		<token id="29" lemma="War" pos="NP" surface="War"/>
		<token id="30" lemma="of" pos="in" surface="of"/>
		<token id="31" lemma="1990" pos="cd" surface="1990"/>
		<token id="32" lemma="," pos="," surface=","/>
		<token id="33" lemma="Hall" pos="NP" surface="Hall"/>
		<token id="34" lemma="'s" pos="POS" surface="'s"/>
		<token id="35" lemma="office" pos="nn" surface="office"/>
		<token id="36" lemma="said" pos="VVD" surface="said"/>
		<token id="37" lemma="Monday" pos="NP" surface="Monday"/>
		<token id="38" lemma="." pos="sent" surface="."/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Entering">
				<lexicalUnit>
					<token id="13"/>
				</lexicalUnit>
				<frameElement type="Theme">
					<token id="8"/>
					<token id="9"/>
					<token id="10"/>
					<token id="11"/>
					<token id="12"/>
				</frameElement>
				<frameElement type="Goal">
					<token id="14"/>
					<token id="15"/>
				</frameElement>
				<frameElement type="Time">
					<token id="16"/>
					<token id="17"/>
				</frameElement>
				<frameElement type="Purpose">
					<token id="18"/>
					<token id="19"/>
					<token id="20"/>
					<token id="21"/>
					<token id="22"/>
					<token id="23"/>
					<token id="24"/>
					<token id="25"/>
					<token id="26"/>
					<token id="27"/>
					<token id="28"/>
					<token id="29"/>
					<token id="30"/>
					<token id="31"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
