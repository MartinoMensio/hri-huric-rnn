<?xml version="1.0" encoding="utf-8"?>
<command id="4096660">
	<sentence>And while this claim has not yet been substantiated by IAEA inspectors , proponents argue that Iran has violated the NPT and that the country 's nuclear file should , in turn , be referred to the United Nations Security Council ( UNSC ) for its review .</sentence>
	<tokens>
		<token id="1" lemma="And" pos="cc" surface="And"/>
		<token id="2" lemma="while" pos="in" surface="while"/>
		<token id="3" lemma="this" pos="dt" surface="this"/>
		<token id="4" lemma="claim" pos="nn" surface="claim"/>
		<token id="5" lemma="has" pos="VHZ" surface="has"/>
		<token id="6" lemma="not" pos="rb" surface="not"/>
		<token id="7" lemma="yet" pos="rb" surface="yet"/>
		<token id="8" lemma="been" pos="VBN" surface="been"/>
		<token id="9" lemma="substantiated" pos="VVN" surface="substantiated"/>
		<token id="10" lemma="by" pos="in" surface="by"/>
		<token id="11" lemma="IAEA" pos="nn" surface="IAEA"/>
		<token id="12" lemma="inspectors" pos="nns" surface="inspectors"/>
		<token id="13" lemma="," pos="," surface=","/>
		<token id="14" lemma="proponents" pos="nns" surface="proponents"/>
		<token id="15" lemma="argue" pos="VVP" surface="argue"/>
		<token id="16" lemma="that" pos="in" surface="that"/>
		<token id="17" lemma="Iran" pos="NP" surface="Iran"/>
		<token id="18" lemma="has" pos="VHZ" surface="has"/>
		<token id="19" lemma="violated" pos="VVN" surface="violated"/>
		<token id="20" lemma="the" pos="dt" surface="the"/>
		<token id="21" lemma="NPT" pos="NP" surface="NPT"/>
		<token id="22" lemma="and" pos="cc" surface="and"/>
		<token id="23" lemma="that" pos="in" surface="that"/>
		<token id="24" lemma="the" pos="dt" surface="the"/>
		<token id="25" lemma="country" pos="nn" surface="country"/>
		<token id="26" lemma="'s" pos="POS" surface="'s"/>
		<token id="27" lemma="nuclear" pos="jj" surface="nuclear"/>
		<token id="28" lemma="file" pos="nn" surface="file"/>
		<token id="29" lemma="should" pos="md" surface="should"/>
		<token id="30" lemma="," pos="," surface=","/>
		<token id="31" lemma="in" pos="in" surface="in"/>
		<token id="32" lemma="turn" pos="nn" surface="turn"/>
		<token id="33" lemma="," pos="," surface=","/>
		<token id="34" lemma="be" pos="vb" surface="be"/>
		<token id="35" lemma="referred" pos="VVN" surface="referred"/>
		<token id="36" lemma="to" pos="to" surface="to"/>
		<token id="37" lemma="the" pos="dt" surface="the"/>
		<token id="38" lemma="United" pos="NP" surface="United"/>
		<token id="39" lemma="Nations" pos="NPS" surface="Nations"/>
		<token id="40" lemma="Security" pos="NP" surface="Security"/>
		<token id="41" lemma="Council" pos="NP" surface="Council"/>
		<token id="42" lemma="(" pos="(" surface="("/>
		<token id="43" lemma="UNSC" pos="NP" surface="UNSC"/>
		<token id="44" lemma=")" pos=")" surface=")"/>
		<token id="45" lemma="for" pos="in" surface="for"/>
		<token id="46" lemma="its" pos="PP$" surface="its"/>
		<token id="47" lemma="review" pos="nn" surface="review"/>
		<token id="48" lemma="." pos="sent" surface="."/>
	</tokens>
	<semantics>
		<frameSemantics>
			<frame name="Searching">
				<lexicalUnit>
					<token id="12"/>
				</lexicalUnit>
				<frameElement type="Cognizer">
					<token id="12"/>
				</frameElement>
			</frame>
		</frameSemantics>
	</semantics>
</command>
