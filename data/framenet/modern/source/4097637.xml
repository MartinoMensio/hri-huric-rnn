<?xml version="1.0" encoding="utf-8"?>
<command id="4097637">
 <sentence>
  Key data sources for DPRK include defector testimony , which may be unreliable given possibility of deliberate disinformation by double agents and defectors exaggerating what they know , and unclassified estimates by US intelligence agencies , which may have certain biases based on national interest , worst - case expectations , domestic politics , etc. Also , most estimates do not rely on original texts in Korean , which may introduce some errors due to translation issues .
 </sentence>
 <tokens>
  <token id="1" lemma="key" pos="JJ" surface="Key"/>
  <token id="2" lemma="datum" pos="NNS" surface="data"/>
  <token id="3" lemma="source" pos="NNS" surface="sources"/>
  <token id="4" lemma="for" pos="IN" surface="for"/>
  <token id="5" lemma="dprk" pos="NNP" surface="DPRK"/>
  <token id="6" lemma="include" pos="VBP" surface="include"/>
  <token id="7" lemma="defector" pos="NN" surface="defector"/>
  <token id="8" lemma="testimony" pos="NN" surface="testimony"/>
  <token id="9" lemma="," pos="," surface=","/>
  <token id="10" lemma="which" pos="WDT" surface="which"/>
  <token id="11" lemma="may" pos="MD" surface="may"/>
  <token id="12" lemma="be" pos="VB" surface="be"/>
  <token id="13" lemma="unreliable" pos="JJ" surface="unreliable"/>
  <token id="14" lemma="give" pos="VBN" surface="given"/>
  <token id="15" lemma="possibility" pos="NN" surface="possibility"/>
  <token id="16" lemma="of" pos="IN" surface="of"/>
  <token id="17" lemma="deliberate" pos="JJ" surface="deliberate"/>
  <token id="18" lemma="disinformation" pos="NN" surface="disinformation"/>
  <token id="19" lemma="by" pos="IN" surface="by"/>
  <token id="20" lemma="double" pos="JJ" surface="double"/>
  <token id="21" lemma="agent" pos="NNS" surface="agents"/>
  <token id="22" lemma="and" pos="CC" surface="and"/>
  <token id="23" lemma="defector" pos="NNS" surface="defectors"/>
  <token id="24" lemma="exaggerate" pos="VBG" surface="exaggerating"/>
  <token id="25" lemma="what" pos="WP" surface="what"/>
  <token id="26" lemma="-PRON-" pos="PRP" surface="they"/>
  <token id="27" lemma="know" pos="VBP" surface="know"/>
  <token id="28" lemma="," pos="," surface=","/>
  <token id="29" lemma="and" pos="CC" surface="and"/>
  <token id="30" lemma="unclassified" pos="JJ" surface="unclassified"/>
  <token id="31" lemma="estimate" pos="NNS" surface="estimates"/>
  <token id="32" lemma="by" pos="IN" surface="by"/>
  <token id="33" lemma="us" pos="NNP" surface="US"/>
  <token id="34" lemma="intelligence" pos="NN" surface="intelligence"/>
  <token id="35" lemma="agency" pos="NNS" surface="agencies"/>
  <token id="36" lemma="," pos="," surface=","/>
  <token id="37" lemma="which" pos="WDT" surface="which"/>
  <token id="38" lemma="may" pos="MD" surface="may"/>
  <token id="39" lemma="have" pos="VB" surface="have"/>
  <token id="40" lemma="certain" pos="JJ" surface="certain"/>
  <token id="41" lemma="bias" pos="NNS" surface="biases"/>
  <token id="42" lemma="base" pos="VBN" surface="based"/>
  <token id="43" lemma="on" pos="IN" surface="on"/>
  <token id="44" lemma="national" pos="JJ" surface="national"/>
  <token id="45" lemma="interest" pos="NN" surface="interest"/>
  <token id="46" lemma="," pos="," surface=","/>
  <token id="47" lemma="bad" pos="JJS" surface="worst"/>
  <token id="48" lemma="-" pos="HYPH" surface="-"/>
  <token id="49" lemma="case" pos="NN" surface="case"/>
  <token id="50" lemma="expectation" pos="NNS" surface="expectations"/>
  <token id="51" lemma="," pos="," surface=","/>
  <token id="52" lemma="domestic" pos="JJ" surface="domestic"/>
  <token id="53" lemma="politic" pos="NNS" surface="politics"/>
  <token id="54" lemma="," pos="," surface=","/>
  <token id="55" lemma="etc." pos="FW" surface="etc."/>
  <token id="56" lemma="also" pos="RB" surface="Also"/>
  <token id="57" lemma="," pos="," surface=","/>
  <token id="58" lemma="most" pos="JJS" surface="most"/>
  <token id="59" lemma="estimate" pos="NNS" surface="estimates"/>
  <token id="60" lemma="do" pos="VBP" surface="do"/>
  <token id="61" lemma="not" pos="RB" surface="not"/>
  <token id="62" lemma="rely" pos="VB" surface="rely"/>
  <token id="63" lemma="on" pos="IN" surface="on"/>
  <token id="64" lemma="original" pos="JJ" surface="original"/>
  <token id="65" lemma="text" pos="NNS" surface="texts"/>
  <token id="66" lemma="in" pos="IN" surface="in"/>
  <token id="67" lemma="korean" pos="NNP" surface="Korean"/>
  <token id="68" lemma="," pos="," surface=","/>
  <token id="69" lemma="which" pos="WDT" surface="which"/>
  <token id="70" lemma="may" pos="MD" surface="may"/>
  <token id="71" lemma="introduce" pos="VB" surface="introduce"/>
  <token id="72" lemma="some" pos="DT" surface="some"/>
  <token id="73" lemma="error" pos="NNS" surface="errors"/>
  <token id="74" lemma="due" pos="JJ" surface="due"/>
  <token id="75" lemma="to" pos="IN" surface="to"/>
  <token id="76" lemma="translation" pos="NN" surface="translation"/>
  <token id="77" lemma="issue" pos="NNS" surface="issues"/>
  <token id="78" lemma="." pos="." surface="."/>
 </tokens>
 <dependencies>
  <dep from="3" to="1" type="amod"/>
  <dep from="3" to="2" type="compound"/>
  <dep from="6" to="3" type="nsubj"/>
  <dep from="3" to="4" type="prep"/>
  <dep from="4" to="5" type="pobj"/>
  <dep from="0" to="6" type="root"/>
  <dep from="8" to="7" type="compound"/>
  <dep from="6" to="8" type="dobj"/>
  <dep from="8" to="9" type="punct"/>
  <dep from="12" to="10" type="nsubj"/>
  <dep from="12" to="11" type="aux"/>
  <dep from="8" to="12" type="relcl"/>
  <dep from="12" to="13" type="acomp"/>
  <dep from="12" to="14" type="prep"/>
  <dep from="14" to="15" type="pobj"/>
  <dep from="15" to="16" type="prep"/>
  <dep from="18" to="17" type="amod"/>
  <dep from="16" to="18" type="pobj"/>
  <dep from="18" to="19" type="prep"/>
  <dep from="21" to="20" type="amod"/>
  <dep from="19" to="21" type="pobj"/>
  <dep from="21" to="22" type="cc"/>
  <dep from="21" to="23" type="conj"/>
  <dep from="18" to="24" type="acl"/>
  <dep from="27" to="25" type="dobj"/>
  <dep from="27" to="26" type="nsubj"/>
  <dep from="24" to="27" type="ccomp"/>
  <dep from="18" to="28" type="punct"/>
  <dep from="18" to="29" type="cc"/>
  <dep from="31" to="30" type="amod"/>
  <dep from="18" to="31" type="conj"/>
  <dep from="31" to="32" type="prep"/>
  <dep from="35" to="33" type="compound"/>
  <dep from="35" to="34" type="compound"/>
  <dep from="32" to="35" type="pobj"/>
  <dep from="35" to="36" type="punct"/>
  <dep from="39" to="37" type="nsubj"/>
  <dep from="39" to="38" type="aux"/>
  <dep from="35" to="39" type="relcl"/>
  <dep from="41" to="40" type="amod"/>
  <dep from="39" to="41" type="dobj"/>
  <dep from="41" to="42" type="acl"/>
  <dep from="42" to="43" type="prep"/>
  <dep from="45" to="44" type="amod"/>
  <dep from="43" to="45" type="pobj"/>
  <dep from="45" to="46" type="punct"/>
  <dep from="49" to="47" type="amod"/>
  <dep from="49" to="48" type="punct"/>
  <dep from="50" to="49" type="compound"/>
  <dep from="45" to="50" type="conj"/>
  <dep from="50" to="51" type="punct"/>
  <dep from="53" to="52" type="amod"/>
  <dep from="50" to="53" type="conj"/>
  <dep from="53" to="54" type="punct"/>
  <dep from="53" to="55" type="conj"/>
  <dep from="39" to="56" type="advmod"/>
  <dep from="62" to="57" type="punct"/>
  <dep from="59" to="58" type="amod"/>
  <dep from="62" to="59" type="nsubj"/>
  <dep from="62" to="60" type="aux"/>
  <dep from="62" to="61" type="neg"/>
  <dep from="6" to="62" type="conj"/>
  <dep from="62" to="63" type="prep"/>
  <dep from="65" to="64" type="amod"/>
  <dep from="63" to="65" type="pobj"/>
  <dep from="65" to="66" type="prep"/>
  <dep from="66" to="67" type="pobj"/>
  <dep from="65" to="68" type="punct"/>
  <dep from="71" to="69" type="nsubj"/>
  <dep from="71" to="70" type="aux"/>
  <dep from="65" to="71" type="relcl"/>
  <dep from="73" to="72" type="det"/>
  <dep from="71" to="73" type="dobj"/>
  <dep from="73" to="74" type="amod"/>
  <dep from="74" to="75" type="pcomp"/>
  <dep from="77" to="76" type="compound"/>
  <dep from="74" to="77" type="pobj"/>
  <dep from="6" to="78" type="punct"/>
 </dependencies>
 <semantics>
  <frameSemantics>
   <frame name="Source_of_getting">
    <lexicalUnit>
     <token id="3"/>
    </lexicalUnit>
    <frameElement type="Theme">
     <token id="2"/>
    </frameElement>
    <frameElement type="Source">
     <token id="3"/>
    </frameElement>
    <frameElement type="Descriptor">
     <token id="1"/>
    </frameElement>
    <frameElement type="Theme">
     <token id="4"/>
     <token id="5"/>
    </frameElement>
   </frame>
   <frame name="Inclusion">
    <lexicalUnit>
     <token id="6"/>
    </lexicalUnit>
    <frameElement type="Total">
     <token id="1"/>
     <token id="2"/>
     <token id="3"/>
     <token id="4"/>
     <token id="5"/>
    </frameElement>
    <frameElement type="Part">
     <token id="7"/>
     <token id="8"/>
     <token id="9"/>
     <token id="10"/>
     <token id="11"/>
     <token id="12"/>
     <token id="13"/>
     <token id="14"/>
     <token id="15"/>
     <token id="16"/>
     <token id="17"/>
     <token id="18"/>
     <token id="19"/>
     <token id="20"/>
     <token id="21"/>
     <token id="22"/>
     <token id="23"/>
     <token id="24"/>
     <token id="25"/>
     <token id="26"/>
     <token id="27"/>
     <token id="28"/>
     <token id="29"/>
     <token id="30"/>
     <token id="31"/>
     <token id="32"/>
     <token id="33"/>
     <token id="34"/>
     <token id="35"/>
     <token id="36"/>
     <token id="37"/>
     <token id="38"/>
     <token id="39"/>
     <token id="40"/>
     <token id="41"/>
     <token id="42"/>
     <token id="43"/>
     <token id="44"/>
     <token id="45"/>
     <token id="46"/>
     <token id="47"/>
     <token id="48"/>
     <token id="49"/>
     <token id="50"/>
     <token id="51"/>
     <token id="52"/>
     <token id="53"/>
     <token id="54"/>
     <token id="55"/>
    </frameElement>
   </frame>
   <frame name="Likelihood">
    <lexicalUnit>
     <token id="15"/>
    </lexicalUnit>
    <frameElement type="Hypothetical_event">
     <token id="16"/>
     <token id="17"/>
     <token id="18"/>
     <token id="19"/>
     <token id="20"/>
     <token id="21"/>
     <token id="22"/>
     <token id="23"/>
     <token id="24"/>
     <token id="25"/>
     <token id="26"/>
     <token id="27"/>
    </frameElement>
   </frame>
   <frame name="Estimated_value">
    <lexicalUnit>
     <token id="31"/>
    </lexicalUnit>
    <frameElement type="Cognizer">
     <token id="32"/>
     <token id="33"/>
     <token id="34"/>
     <token id="35"/>
    </frameElement>
    <frameElement type="Value">
     <token id="31"/>
    </frameElement>
   </frame>
   <frame name="Partiality">
    <lexicalUnit>
     <token id="41"/>
    </lexicalUnit>
    <frameElement type="Decision_maker">
     <token id="37"/>
    </frameElement>
    <frameElement type="Decision_maker">
     <token id="33"/>
     <token id="34"/>
     <token id="35"/>
    </frameElement>
   </frame>
   <frame name="Awareness">
    <lexicalUnit>
     <token id="27"/>
    </lexicalUnit>
    <frameElement type="Cognizer">
     <token id="26"/>
    </frameElement>
    <frameElement type="Content">
     <token id="25"/>
    </frameElement>
   </frame>
   <frame name="Information">
    <lexicalUnit>
     <token id="34"/>
    </lexicalUnit>
    <frameElement type="Information">
     <token id="34"/>
    </frameElement>
   </frame>
   <frame name="Estimated_value">
    <lexicalUnit>
     <token id="59"/>
    </lexicalUnit>
    <frameElement type="Value">
     <token id="59"/>
    </frameElement>
   </frame>
   <frame name="Foreign_or_domestic_country">
    <lexicalUnit>
     <token id="52"/>
    </lexicalUnit>
    <frameElement type="Current_country">
     <token id="52"/>
    </frameElement>
   </frame>
   <frame name="Importance">
    <lexicalUnit>
     <token id="1"/>
    </lexicalUnit>
    <frameElement type="Factor">
     <token id="2"/>
     <token id="3"/>
     <token id="4"/>
     <token id="5"/>
    </frameElement>
   </frame>
   <frame name="Emotion_directed">
    <lexicalUnit>
     <token id="45"/>
    </lexicalUnit>
    <frameElement type="Experiencer">
     <token id="44"/>
    </frameElement>
   </frame>
   <frame name="Political_locales">
    <lexicalUnit>
     <token id="44"/>
    </lexicalUnit>
    <frameElement type="Locale">
     <token id="44"/>
    </frameElement>
   </frame>
   <frame name="Desirability">
    <lexicalUnit>
     <token id="47"/>
    </lexicalUnit>
    <frameElement type="Evaluee">
     <token id="49"/>
    </frameElement>
   </frame>
   <frame name="Translating">
    <lexicalUnit>
     <token id="76"/>
    </lexicalUnit>
   </frame>
   <frame name="Secrecy_status">
    <lexicalUnit>
     <token id="30"/>
    </lexicalUnit>
    <frameElement type="Phenomenon">
     <token id="31"/>
    </frameElement>
   </frame>
   <frame name="People_by_vocation">
    <lexicalUnit>
     <token id="20"/>
    </lexicalUnit>
    <frameElement type="Person">
     <token id="20"/>
     <token id="21"/>
    </frameElement>
   </frame>
  </frameSemantics>
 </semantics>
</command>