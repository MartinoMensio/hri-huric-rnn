{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity of dataset for semantic parsing\n",
    "\n",
    "Measures from [\"Sources of Complexity in Semantic Frame Parsing for Information Extraction\"](https://hal.archives-ouvertes.fr/hal-01731385/document)\n",
    "\n",
    "The goal is to analyze the complexity of the HuRIC corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "DATASET_LOCATION = '../data/huric_eb/modern/source'\n",
    "\n",
    "def load_xmls(folder):\n",
    "    path = Path(folder)\n",
    "    files_list = [el for el in path.iterdir() if el.is_file()]\n",
    "    file_contents = []\n",
    "    for file in sorted(files_list):\n",
    "        with open(file) as file_in:\n",
    "            tree = ET.parse(file_in)\n",
    "        root = tree.getroot()\n",
    "        file_contents.append(root)\n",
    "    return file_contents\n",
    "\n",
    "def get_lu_pos(root, verbose=False):\n",
    "    \"\"\"Returns the POS for all the LU in the current document\"\"\"\n",
    "    w_id_to_pos = {t.attrib['id']: t.attrib['pos'] for t in root.findall('tokens/token')}\n",
    "    #print(w_id_to_pos)\n",
    "    lu_idxs = [lu.attrib['id'] for lu in root.findall('semantics/frameSemantics/frame/lexicalUnit/token')]\n",
    "    #print(lu_idxs)\n",
    "    lu_pos = [w_id_to_pos[id] for id in lu_idxs]\n",
    "    if verbose:\n",
    "        print(root.attrib['id'], lu_pos)\n",
    "    return lu_pos\n",
    "\n",
    "def get_lu_are_roots(root, verbose=False):\n",
    "    \"\"\"Returns whether the lexicalUnits are the roots in dependencies\"\"\"\n",
    "    roots_id = [d.attrib['to'] for d in root.findall('dependencies/dep') if d.attrib['type'] == 'root']\n",
    "    lu_idxs = [lu.attrib['id'] for lu in root.findall('semantics/frameSemantics/frame/lexicalUnit/token')]\n",
    "    lu_are_roots = [l in roots_id for l in lu_idxs]\n",
    "    if verbose:\n",
    "        print(root.attrib['id'], lu_are_roots)\n",
    "    return lu_are_roots\n",
    "\n",
    "def get_lengths(root, verbose=False):\n",
    "    \"\"\"Returns the length of the command\"\"\"\n",
    "    # TODO shouldn't be frame-based? find min and max token id and do difference\n",
    "    return [len(root.findall('tokens/token'))]\n",
    "\n",
    "def get_lu_depths(root, verbose=False):\n",
    "    \"\"\"Returns the depths in the dependency tree of the lexicalUnits\"\"\"\n",
    "    # TODO the depth should be relative to the frame\n",
    "    edges = [(d.attrib['from'], d.attrib['to'], d.attrib['type']) for d in root.findall('dependencies/dep')]\n",
    "    #print(edges)\n",
    "    to_father = {e[1]: e[0] for e in edges}\n",
    "    depths = {}\n",
    "    for el, f in to_father.items():\n",
    "        current_el = el\n",
    "        depth = 0\n",
    "        # the root has id == '0', the second condition is only to avoid infinite looping\n",
    "        while f != '0' and depth < len(edges):\n",
    "            depth += 1\n",
    "            current_el = f\n",
    "            f = to_father[current_el]\n",
    "        if f != '0':\n",
    "            # broken annotations\n",
    "            depth = -1\n",
    "        depths[el] = depth\n",
    "    lu_idxs = [lu.attrib['id'] for lu in root.findall('semantics/frameSemantics/frame/lexicalUnit/token')]\n",
    "    lu_depths = [depths[l] for l in lu_idxs]\n",
    "    if verbose:\n",
    "        print(root.attrib['id'], lu_depths)\n",
    "    return lu_depths\n",
    "\n",
    "def get_lu_positions(root, verbose=False):\n",
    "    \"\"\"Get the position of lexicalUnits in the command\"\"\"\n",
    "    # TODO the position should be relative to the frame\n",
    "    lu_idxs = [lu.attrib['id'] for lu in root.findall('semantics/frameSemantics/frame/lexicalUnit/token')]\n",
    "    lu_positions = [int(l) for l in lu_idxs]\n",
    "    return lu_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lu_pos [('VB', 537), ('VBZ', 31), ('EX', 13), ('VBD', 12), ('VBN', 5), ('RP', 3), ('NN', 1)]\n",
      "lu_are_roots [(False, 114), (True, 488)]\n",
      "lengths [(2, 1), (3, 41), (4, 71), (5, 40), (6, 77), (7, 105), (8, 51), (9, 51), (10, 27), (11, 18), (12, 11), (13, 10), (14, 10), (15, 6), (16, 1), (17, 3), (18, 1), (19, 1), (20, 1)]\n",
      "lu_depths [(0, 488), (1, 100), (2, 13), (3, 1)]\n",
      "lu_positions [(1, 342), (2, 77), (3, 55), (4, 50), (5, 11), (6, 18), (7, 11), (8, 13), (9, 8), (10, 4), (11, 6), (12, 3), (14, 3), (15, 1)]\n"
     ]
    }
   ],
   "source": [
    "xml_docs = load_xmls(DATASET_LOCATION)\n",
    "lu_pos_all = defaultdict(lambda: 0)\n",
    "lu_are_roots_all = defaultdict(lambda: 0)\n",
    "lengths_all = defaultdict(lambda: 0)\n",
    "lu_depths_all = defaultdict(lambda: 0)\n",
    "lu_positions_all = defaultdict(lambda: 0)\n",
    "for doc in xml_docs:\n",
    "    lu_pos = get_lu_pos(doc)\n",
    "    for p in lu_pos:\n",
    "        lu_pos_all[p] += 1\n",
    "    lu_are_roots = get_lu_are_roots(doc)\n",
    "    for r in lu_are_roots:\n",
    "        lu_are_roots_all[r] += 1\n",
    "    lengths = get_lengths(doc)\n",
    "    for l in lengths:\n",
    "        lengths_all[l] += 1\n",
    "    lu_depths = get_lu_depths(doc)\n",
    "    for d in lu_depths:\n",
    "        lu_depths_all[d] += 1\n",
    "    lu_positions = get_lu_positions(doc)\n",
    "    for p in lu_positions:\n",
    "        lu_positions_all[p] += 1\n",
    "    \n",
    "print('lu_pos', sorted(lu_pos_all.items(), key=lambda x: x[1], reverse=True))\n",
    "print('lu_are_roots', sorted(lu_are_roots_all.items()))\n",
    "print('lengths', sorted(lengths_all.items()))\n",
    "print('lu_depths', sorted(lu_depths_all.items()))\n",
    "print('lu_positions', sorted(lu_positions_all.items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
