{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import utils\n",
    "\n",
    "H_ONLY='../nlunetwork/results/tuning/optimized/h_only/conf_4/huric/modern_right/'\n",
    "FN_FT='../nlunetwork/results/tuning/optimized/fn_only_hyper_h/huric/modern_right/'\n",
    "FN_LU='../nlunetwork/results/tuning/optimized/fn_lu_only_hyper_h/huric/modern_right/'\n",
    "H_FN_FT='../nlunetwork/results/tuning/optimized/h_and_fn_ft/conf_4/huric/with_framenet_ft/'\n",
    "H_FN_LU='../nlunetwork/results/tuning/optimized/h_and_fn_lu/conf_4/huric/with_framenet_lu/'\n",
    "\n",
    "samples_h = utils.load_json(H_ONLY,16)\n",
    "#samples_fn_ft = utils.load_json(FN_FT, 0)\n",
    "samples_fn = utils.load_json(FN_LU, 0)\n",
    "#samples_h_fn_ft = utils.load_json(H_FN_FT,48)\n",
    "samples_h_fn = utils.load_json(H_FN_LU,25)\n",
    "\n",
    "# also the XML stuff\n",
    "HURIC_LOCATION = '../data/huric/modern/source'\n",
    "gold_attn = utils.load_attention_gold('../data/huric/modern_right/lu_disc_final.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_align_array(pred_attn_vals, gold_one_hot):\n",
    "    # how many targets are there (non-zero elements)\n",
    "    n_targets = sum(gold_one_hot)\n",
    "    # take n_targets best values from the predicted attention values\n",
    "    if n_targets:\n",
    "        pred_target_indexes = np.argpartition(pred_attn_vals, -n_targets)[-n_targets:]\n",
    "    else:\n",
    "        # just be careful when n_targets is zero, argpartition would return all the indexes\n",
    "        pred_target_indexes = []\n",
    "    # now from the indexes found, get the 0/1 representation\n",
    "    pred_targets = [1 if el in pred_target_indexes else 0 for el in range(len(pred_attn_vals))]\n",
    "    #print(n_targets, pred_target_indexes, gold_one_hot, pred_targets)\n",
    "    # and get the f1 score only on the 1 class (average is binary)    \n",
    "    f1 = f1_score(gold_one_hot, pred_targets, average='binary')\n",
    "    return f1\n",
    "\n",
    "def evaluate_attn(samples, golds):\n",
    "    total = defaultdict(lambda: 0)\n",
    "    total_only_correct = defaultdict(lambda: 0)\n",
    "    correct_frame_cnt = 0\n",
    "    for s in samples:\n",
    "        #print(s['id'])\n",
    "        gold = golds[str(s['id'])]\n",
    "        for what in ['lu', 'lu+disc', 'lu+disc2']:\n",
    "            gold_one_hot = gold[what]\n",
    "            measure = eval_align_array(s['intent_attentions'], gold_one_hot)\n",
    "            total[what] += measure\n",
    "        if gold['frame'] == s['intent_pred']:\n",
    "            correct_frame_cnt += 1\n",
    "            for what in ['lu', 'lu+disc', 'lu+disc2']:\n",
    "                gold_one_hot = gold[what]\n",
    "                measure = eval_align_array(s['intent_attentions'], gold_one_hot)\n",
    "                total_only_correct['only_correct_frame_{}'.format(what)] += measure\n",
    "    for what, val in total.items():\n",
    "        print(what, val/len(samples))\n",
    "    for what, val in total_only_correct.items():\n",
    "        print(what, val/correct_frame_cnt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lu 0.0636998254799302\n",
      "lu+disc 0.1273996509598604\n",
      "lu+disc2 0.14761489237929026\n",
      "only_correct_frame_lu 0.0625\n",
      "only_correct_frame_lu+disc 0.12409420289855072\n",
      "only_correct_frame_lu+disc2 0.1444746376811594\n"
     ]
    }
   ],
   "source": [
    "evaluate_attn(samples_h, gold_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lu 0.9511343804537522\n",
      "lu+disc 0.8685282140779523\n",
      "lu+disc2 0.8454043048283887\n",
      "only_correct_frame_lu 0.9923076923076923\n",
      "only_correct_frame_lu+disc 0.8884615384615384\n",
      "only_correct_frame_lu+disc2 0.8867521367521367\n"
     ]
    }
   ],
   "source": [
    "evaluate_attn(samples_fn, gold_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lu 0.44851657940663175\n",
      "lu+disc 0.45898778359511344\n",
      "lu+disc2 0.4714950552646888\n",
      "only_correct_frame_lu 0.4601593625498008\n",
      "only_correct_frame_lu+disc 0.4677954847277556\n",
      "only_correct_frame_lu+disc2 0.48240371845949526\n"
     ]
    }
   ],
   "source": [
    "evaluate_attn(samples_h_fn, gold_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
